{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img,text=None,should_save=False):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(65, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()\n",
    "\n",
    "class Config():\n",
    "    training_dir = \"att_faces/training/\"\n",
    "    testing_dir = \"att_faces/testing/\"\n",
    "    train_batch_size = 64\n",
    "    train_number_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,imageFolderDataset,transform=None,should_invert=True,should_gray=True):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "        self.should_gray = should_gray        \n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
    "        #we need to make sure approx 50% of images are in the same class\n",
    "        should_get_same_class = random.randint(0,1) \n",
    "        if should_get_same_class:\n",
    "            while True:\n",
    "                #keep looping till the same class image is found\n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1]==img1_tuple[1]:\n",
    "                    break\n",
    "        else:\n",
    "            while True:\n",
    "                #keep looping till a different class image is found\n",
    "                \n",
    "                img1_tuple = random.choice(self.imageFolderDataset.imgs) \n",
    "                if img0_tuple[1] !=img1_tuple[1]:\n",
    "                    break\n",
    "\n",
    "        img0 = Image.open(img0_tuple[0])\n",
    "        img1 = Image.open(img1_tuple[0])\n",
    "        \n",
    "        if self.should_gray:\n",
    "            img0 = img0.convert(\"L\")\n",
    "            img1 = img1.convert(\"L\")\n",
    "        \n",
    "        if self.should_invert:\n",
    "            img0 = PIL.ImageOps.invert(img0)\n",
    "            img1 = PIL.ImageOps.invert(img1)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1 , torch.from_numpy(np.array([int(img1_tuple[1]!=img0_tuple[1])],dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # TODO: design the architecture\n",
    "        self.conv1 = nn.Conv2d(1,8,3,padding=1)\n",
    "        self.maxPool1 = nn.MaxPool2d(2)\n",
    "        # ReLU\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8,16,3,padding=1)\n",
    "        self.maxPool2 = nn.MaxPool2d(2)\n",
    "        # ReLU\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16,32,3,padding=1)\n",
    "        self.maxPool3 = nn.MaxPool2d(2)\n",
    "        # ReLU\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.fc1 = nn.Linear(4608, 1024)\n",
    "        # ReLU\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        # ReLU\n",
    "        self.fc3 = nn.Linear(512, 8)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        #TODO: implement the forward pass to get features for input image        \n",
    "        z1 = self.conv1(x)\n",
    "        m1 = self.maxPool1(z1)\n",
    "        a1 = F.relu(m1)\n",
    "        a1 = self.bn1(a1)\n",
    "                \n",
    "        z2 = self.conv2(a1)\n",
    "        m2 = self.maxPool2(z2)\n",
    "        a2 = F.relu(m2)\n",
    "        a2 = self.bn2(a2)\n",
    "                \n",
    "        z3 = self.conv3(a2)\n",
    "        m3 = self.maxPool3(z3)\n",
    "        a3 = F.relu(m3)\n",
    "        a3 = self.bn3(a3)\n",
    "\n",
    "        z4 = self.fc1(a3.view(a3.shape[0], -1))\n",
    "        a4 = F.relu(z4)\n",
    "                \n",
    "        z5 = self.fc2(a4)\n",
    "        a5 = F.relu(z5)\n",
    "        \n",
    "        z6 = self.fc3(a5)\n",
    "        \n",
    "        return z6\n",
    "        \n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Contrastive loss function.\n",
    "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        #TODO: argument output1 is f(x1), output2 is f(x2)\n",
    "        # calculate the contrastive loss and return it\n",
    "        euc_distances = F.pairwise_distance(output1, output2).view(-1,1)\n",
    "        loss = (1-label)*(euc_distances**2) + label*(((self.margin - euc_distances).clamp(min=0))**2)\n",
    "        loss = torch.mean(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataiter, net, split, device):\n",
    "    for i in range(2):\n",
    "        x0,_,_ = next(dataiter)\n",
    "        for j in range(10):\n",
    "            _,x1,_ = next(dataiter)\n",
    "            concatenated = torch.cat((x0,x1),0)\n",
    "            output1,output2 = net(Variable(x0).to(device),Variable(x1).to(device))\n",
    "            euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "            imshow(torchvision.utils.make_grid(concatenated),'%s, dissimilarity:%.2f'%(split, euclidean_distance.item())) \n",
    "            plt.savefig('%s_%d_%d.png'%(split,i, j))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 0\n",
      " Current loss 2.004492998123169\n",
      "\n",
      "Epoch number 1\n",
      " Current loss 0.4032353162765503\n",
      "\n",
      "Epoch number 2\n",
      " Current loss 0.32568204402923584\n",
      "\n",
      "Epoch number 3\n",
      " Current loss 0.2171175181865692\n",
      "\n",
      "Epoch number 4\n",
      " Current loss 0.20326577126979828\n",
      "\n",
      "Epoch number 5\n",
      " Current loss 0.14600753784179688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder_dataset = dset.ImageFolder(root=Config.training_dir)\n",
    "    \n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset,\n",
    "                                    transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                  transforms.ToTensor()]),\n",
    "                                    should_invert=False)\n",
    "train_dataloader = DataLoader(siamese_dataset, shuffle=True, num_workers=10, batch_size=Config.train_batch_size)   \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = SiameseNetwork().to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.0005)\n",
    "\n",
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "for epoch in range(0,Config.train_number_epochs):\n",
    "    for i, data in enumerate(train_dataloader,0):\n",
    "        img0, img1 , label = data\n",
    "        img0, img1 , label = img0.to(device), img1.to(device) , label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = net(img0,img1)\n",
    "        loss_contrastive = criterion(output1,output2,label)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i %10 == 0 :\n",
    "            print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "\n",
    "train_dataloader = DataLoader(siamese_dataset, shuffle=False, num_workers=10, batch_size=1)\n",
    "dataiter = iter(train_dataloader)\n",
    "evaluate(dataiter, net, 'train', device)\n",
    "\n",
    "folder_dataset_test = dset.ImageFolder(root=Config.testing_dir)\n",
    "siamese_dataset = SiameseNetworkDataset(imageFolderDataset=folder_dataset_test,\n",
    "                                    transform=transforms.Compose([transforms.Resize((100,100)),\n",
    "                                                                  transforms.ToTensor()\n",
    "                                                                  ])\n",
    "                                   ,should_invert=False)\n",
    "\n",
    "test_dataloader = DataLoader(siamese_dataset,num_workers=10,batch_size=1,shuffle=True)\n",
    "dataiter = iter(test_dataloader)\n",
    "evaluate(dataiter, net, 'test', device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
