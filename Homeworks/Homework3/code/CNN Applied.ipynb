{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "from torch import optim\n",
    "from cnn import CNN\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data tools\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "TEXT = data.Field(sequential=True, lower=True, tokenize=tokenizer, fix_length=30)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define datasets\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_val_fields = [('Label', LABEL),('Text', TEXT)]\n",
    "train_set, val_set, test_set = data.TabularDataset.splits(path='data', \n",
    "    format='tsv', \n",
    "    train='train.tsv', \n",
    "    validation='dev.tsv',\n",
    "    test='test.tsv',\n",
    "    fields=train_val_fields, \n",
    "    skip_header=True)\n",
    "\n",
    "unlabelled_fields = [('id', None),('Text', TEXT)]\n",
    "unlabelled_set = data.TabularDataset(path='data/unlabelled.tsv', \n",
    "    format='tsv', \n",
    "    fields=unlabelled_fields, \n",
    "    skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build vocab\n",
    "TEXT.build_vocab(train_set, max_size=100000, vectors='glove.6B.100d')\n",
    "LABEL.build_vocab(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, H, conv_size, out_channels, pretrained_vocab=None):\n",
    "        super(CNN, self).__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size,H)\n",
    "        self.conv1d = nn.Conv1d(H, out_channels, conv_size)\n",
    "        self.avgPool = nn.AdaptiveAvgPool2d((out_channels, 1))\n",
    "        self.linear = nn.Linear(out_channels, 2)\n",
    "        \n",
    "        if pretrained_vocab:\n",
    "            self.embedding.weight.data.copy_(pretrained_vocab.vectors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x).permute(1,2,0)\n",
    "        h_conv1d = self.conv1d(h_embedding)\n",
    "        h_pool = self.avgPool(h_conv1d).clamp(min=0).squeeze()\n",
    "        h_linear = self.linear(h_pool)\n",
    "        logits = F.softmax(h_linear, dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get data iterators\n",
    "train_it_64, val_it_64 = data.Iterator.splits(\n",
    "        (train_set, val_set), sort_key=lambda x: len(x.Text),\n",
    "        batch_size=64, device=device)\n",
    "\n",
    "train_it, val_it = data.Iterator.splits(\n",
    "        (train_set, val_set), sort_key=lambda x: len(x.Text),\n",
    "        batch_size=4, device=device)\n",
    "test_it = data.BucketIterator(\n",
    "    dataset=test_set,\n",
    "    batch_size=1,\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.Text),\n",
    "    shuffle=False)\n",
    "unlabelled_it = data.BucketIterator(\n",
    "    dataset=unlabelled_set,\n",
    "    batch_size=1,\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.Text),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': train_it,\n",
    "    'val': val_it,\n",
    "    'test': test_it,\n",
    "    'unlabelled': unlabelled_it\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helpers\n",
    "def forward(model, batch, criterion, multiclass=True):\n",
    "    if multiclass:\n",
    "            outputs = model(batch.Text).squeeze(1)\n",
    "            _,preds = torch.max(outputs,1)\n",
    "            loss = criterion(outputs, batch.Label)\n",
    "\n",
    "            correct = (preds == batch.Label).float()\n",
    "            acc = correct.sum()/len(correct)\n",
    "    else:\n",
    "        outputs = model(batch.Text).squeeze(1)\n",
    "        loss = criterion(outputs, batch.Label.float())\n",
    "\n",
    "        preds = torch.round(torch.sigmoid(outputs))\n",
    "        correct = (preds == batch.Label.float()).float()\n",
    "        acc = correct.sum()/len(correct)\n",
    "    return loss, acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, multiclass=True):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        loss, acc = forward(model, batch, criterion, multiclass=multiclass)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, multiclass=True):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            loss, acc = forward(model, batch, criterion, multiclass=multiclass)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def run_model(device, dataloaders, model, optimizer, criterion, num_epochs, multiclass=True):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    train_it, val_it, test_it = dataloaders['train'], dataloaders['val'], dataloaders['test']\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train(model, train_it, optimizer, criterion, multiclass=multiclass)\n",
    "        valid_loss, valid_acc = evaluate(model, val_it, criterion, multiclass=multiclass)\n",
    "\n",
    "        print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
    "\n",
    "    test_loss, test_acc = evaluate(model, test_it, criterion, multiclass=multiclass)\n",
    "    print('Test loss:', test_loss)\n",
    "    print('Test accuracy:', test_acc)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train CNN Model (with pretrain)\n",
    "model = CNN(len(TEXT.vocab), 100, , 128, pretrained_vocab=TEXT.vocab)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn_model = run_model(device, dataloaders, model, optimizer, criterion, 25, multiclass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 0.504 | Train Acc: 79.35% | Val. Loss: 0.445 | Val. Acc: 86.11% |\n",
      "| Epoch: 02 | Train Loss: 0.429 | Train Acc: 87.91% | Val. Loss: 0.574 | Val. Acc: 72.99% |\n",
      "| Epoch: 03 | Train Loss: 0.410 | Train Acc: 89.85% | Val. Loss: 0.388 | Val. Acc: 92.07% |\n",
      "| Epoch: 04 | Train Loss: 0.400 | Train Acc: 90.97% | Val. Loss: 0.599 | Val. Acc: 70.63% |\n",
      "| Epoch: 05 | Train Loss: 0.393 | Train Acc: 91.68% | Val. Loss: 0.409 | Val. Acc: 90.06% |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-e55906b59737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-94817ea8d712>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(device, dataloaders, model, optimizer, criterion, num_epochs, multiclass)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-94817ea8d712>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, multiclass)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eecs445/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Train CNN Model (with pretrain)\n",
    "model = CNN(len(TEXT.vocab), 100, 5, 128, pretrained_vocab=TEXT.vocab)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "cnn_model = run_model(device, dataloaders, model, optimizer, criterion, 20, multiclass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
